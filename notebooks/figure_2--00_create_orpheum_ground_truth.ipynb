{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Python standard library\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "# # Third-party libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import screed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# # Local python files\n",
    "from path_constants import (\n",
    "    DATA_FOLDER,\n",
    "    ORPHEUM_BENCHMARKING_FOLDER,\n",
    "    ORPHEUM_GROUND_TRUTH_FOLDER,\n",
    "    QFO_EUKARYOTA_FOLDER,\n",
    "    SIMULATED_RNASEQ_FOLDER,\n",
    "    SIMULATED_READS_FASTQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset to only reads from complete protein sequences -- no fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get good uniprot ids, starting with M amino acid and ATG codon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_protein_starts_with_m = []\n",
    "\n",
    "\n",
    "protein_fasta = os.path.join(\n",
    "    QFO_EUKARYOTA_FOLDER,\n",
    "    \"UP000005640_9606.fasta\",\n",
    ")\n",
    "cdna_fasta = os.path.join(\n",
    "    QFO_EUKARYOTA_FOLDER,\n",
    "    \"UP000005640_9606_DNA.fasta\",\n",
    ")\n",
    "\n",
    "\n",
    "with screed.open(protein_fasta) as records:\n",
    "    for record in records:\n",
    "        if record[\"sequence\"].startswith(\"M\"):\n",
    "            uniprot_protein_starts_with_m.append(\n",
    "                \"|\".join(record[\"name\"].split()[0].split(\"|\")[:2])\n",
    "            )\n",
    "print(\"uniprot_protein_starts_with_m\", len(uniprot_protein_starts_with_m))\n",
    "\n",
    "\n",
    "uniprot_dna_starts_with_atg = []\n",
    "with screed.open(cdna_fasta) as records:\n",
    "    for record in records:\n",
    "        if record[\"sequence\"].startswith(\"ATG\"):\n",
    "            uniprot_dna_starts_with_atg.append(\n",
    "                \"|\".join(record[\"name\"].split()[0].split(\"|\")[:2])\n",
    "            )\n",
    "print(\"uniprot_dna_starts_with_atg\", len(uniprot_dna_starts_with_atg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail $protein_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_dna_starts_with_atg[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_protein_starts_with_m[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_starts_with_atg_and_m = set(uniprot_dna_starts_with_atg).intersection(set(uniprot_protein_starts_with_m))\n",
    "len(uniprot_starts_with_atg_and_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_starts_with_atg_and_m_list = list(uniprot_starts_with_atg_and_m)\n",
    "uniprot_starts_with_atg_and_m_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! grep -c '>' $cdna_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! grep -c '>' $protein_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_dna_starts_with_atg[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write good uniprot ids to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_uniprot_records = []\n",
    "with screed.open(cdna_fasta) as records:\n",
    "    for record in records:\n",
    "        clean_uniprot_id = '|'.join(record['name'].split('|')[:2])\n",
    "        if clean_uniprot_id in uniprot_starts_with_atg_and_m:\n",
    "            good_uniprot_records.append(record)\n",
    "len(good_uniprot_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_uniprot_records[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_fasta_good_uniprot_ids = os.path.join(\n",
    "    QFO_EUKARYOTA_FOLDER,\n",
    "    \"UP000005640_9606_DNA__startswith_atg_and_protein_startswith_m.fasta\",\n",
    ")\n",
    "\n",
    "with open(protein_fasta_good_uniprot_ids, \"w\") as f:\n",
    "    for record in good_uniprot_records:\n",
    "        f.write(f'>{record[\"name\"]}\\n{record[\"sequence\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_uniprot_records_dict = {'|'.join(r['name'].split('|')[:2]): r['sequence'] for r in good_uniprot_records}\n",
    "len(good_uniprot_records_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_uniprot_records_series = pd.Series(good_uniprot_records_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_uniprot_records_dict['tr|A0A024R1R8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_dna_starts_with_atg[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grep dna fasta for the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! grep -A 1 'sp|A0A075B6K2|ENSP00000374848' $cdna_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! zgrep -A 3 'read1000/sp|A0A075B6K2|ENSP00000374848;mate1:5-154;mate2:37-186' $SIMULATED_RNASEQ_FOLDER/*.fq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get read IDs of reads that don't have an `N`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "read_ids_without_n = []\n",
    "with screed.open(SIMULATED_READS_FASTQ) as records:\n",
    "    for record in records:\n",
    "        if \"N\" not in record[\"sequence\"]:\n",
    "            read_ids_without_n.append(record[\"name\"])\n",
    "print(len(read_ids_without_n))\n",
    "read_ids_without_n[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer reading frame from read start -- assume all reads start with ATG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamming distance function\n",
    "\n",
    "from http://claresloggett.github.io/python_workshops/improved_hammingdist.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the Hamming distance between string1 and string2.\n",
    "# string1 and string2 should be the same length.\n",
    "def hamming_distance(string1, string2): \n",
    "    # Start with a distance of zero, and count up\n",
    "    distance = 0\n",
    "    # Loop over the indices of the string\n",
    "    L = len(string1)\n",
    "    for i in range(L):\n",
    "        # Add 1 to the distance if these two characters are not equal\n",
    "        if string1[i] != string2[i]:\n",
    "            distance += 1\n",
    "    # Return the final count of differences\n",
    "    return distance\n",
    "\n",
    "\n",
    "# Reveres complemeent\n",
    "\n",
    "old_chars = \"ACGT\"\n",
    "replace_chars = \"TGCA\"\n",
    "tab = str.maketrans(old_chars,replace_chars)\n",
    "\n",
    "def reverse_complement(sequence):\n",
    "    return sequence.translate(tab)[::-1]\n",
    "\n",
    "def rev_compl(st):\n",
    "    nn = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'}\n",
    "    return \"\".join(nn[n] for n in reversed(st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read 51 is coding in negative frame, and mate2!!\n",
    "\n",
    "```\n",
    "@read51/sp|A0A024RBG1|ENSP00000492425;mate1:130-279;mate2:281-430\n",
    "GCTTTTCCAGATACTCTGCATGTACAGGTTTATGACACTGGAGAACTTTGATAGCATCTTCTACTTTGAACCACTCTCTCTTCCTTCCAATATTAACAGAATCTTCCCAATCTTCTAATATTTCAGTGACTGTTAGAACATAAACATATG\n",
    "+\n",
    "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_distance(good_uniprot_records_dict['sp|A0A024RBG1'][280:429], \n",
    "                 'GCTTTTCCAGATACTCTGCATGTACAGGTTTATGACACTGGAGAACTTTGATAGCATCTTCTACTTTGAACCACTCTCTCTTCCTTCCAATATTAACAGAATCTTCCCAATCTTCTAATATTTCAGTGACTGTTAGAACATAAACATATG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read 52 is coding in positive frame\n",
    "\n",
    "```\n",
    "@read52/sp|A0A024RBG1|ENSP00000492425;mate1:125-274;mate2:193-342\n",
    "ACCCAGACCAGTGGATTGTCCCAGGAGGAGGAATGGAACCCGAGGAGGAACCTGGCGGTGCTGCCGTGAGGGAAGTTTATGAGGAGGCTGGAGTCAAAGGAAAACTAGGCAGACTTCTGGGCATATTTGAGCAGAACCAAGACCGAAAGC\n",
    "+\n",
    "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_distance(good_uniprot_records_dict['sp|A0A024RBG1'][124:273], \n",
    "                 'ACCCAGACCAGTGGATTGTCCCAGGAGGAGGAATGGAACCCGAGGAGGAACCTGGCGGTGCTGCCGTGAGGGAAGTTTATGAGGAGGCTGGAGTCAAAGGAAAACTAGGCAGACTTCTGGGCATATTTGAGCAGAACCAAGACCGAAAGC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to actually infer translation frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# https://regex101.com/r/WNtXD8/1/\n",
    "interval_patterns = 'mate1:(?P<mate1_start>\\d+)-(\\d+);mate2:(\\d+)-(\\d+)'\n",
    "\n",
    "\n",
    "\n",
    "def get_strand(canonical_seq, record_seq):\n",
    "#     import pdb ; pdb.set_trace()\n",
    "    try:\n",
    "        n_mismatches = hamming_distance(canonical_seq, record_seq)\n",
    "    except IndexError:\n",
    "        # Lengths don't match, ignore this read\n",
    "        return None\n",
    "    if n_mismatches > 10:\n",
    "        # Make sure it's really the reverse complement\n",
    "        revcomp = reverse_complement(record_seq)\n",
    "        try:\n",
    "            n_mismatches = hamming_distance(canonical_seq, revcomp)\n",
    "        except IndexError:\n",
    "            # Lengths don't match, ignore this read\n",
    "            return None\n",
    "        # Not too many mismatches\n",
    "        if n_mismatches <= 10:\n",
    "            strand = -1\n",
    "        else:\n",
    "            strand = None\n",
    "    else:\n",
    "        strand = 1\n",
    "#     if strand is None:\n",
    "#         raise ValueError\n",
    "    return strand\n",
    "\n",
    "\n",
    "def get_correct_reading_frame(record, required_length=150, verbose=False):\n",
    "    name = record['name']\n",
    "    if 'mate1Start' in name:\n",
    "        frame = 1\n",
    "    else:\n",
    "        # Subtract 1 since the fastq file uses 1-based indexing for the start/stop but python is 0-based\n",
    "        try:\n",
    "            start1, end1, start2, end2 = map(lambda x: int(x) - 1 , re.findall(interval_patterns, name)[0])\n",
    "        except IndexError:\n",
    "            # Read id has negative values and otherwise doesn't match my mental model --> ignore\n",
    "            return None\n",
    "        \n",
    "        end1 += 1\n",
    "#         start2 += 1\n",
    "        end2 += 1\n",
    "\n",
    "\n",
    "        uniprot_id = '|'.join(name.split(';')[0].split('/')[-1].split('|')[:2])\n",
    "        try:\n",
    "            canonical_sequence = good_uniprot_records_dict[uniprot_id]\n",
    "        except KeyError:\n",
    "            # Uniprot record doesn't have clear start/stop site, so difficult to infer frame --> skip\n",
    "            return None\n",
    "        \n",
    "        canonical_length = len(canonical_sequence)\n",
    "        if end1 > canonical_length or end2 > canonical_length:\n",
    "            # Read extends past the boundary of the source sequence --> skip\n",
    "            return None\n",
    "        \n",
    "\n",
    "        mate1 = canonical_sequence[start1:end1]\n",
    "        mate2 = canonical_sequence[start2:end2]\n",
    "        assert len(mate1) == required_length\n",
    "        assert len(mate2) == required_length\n",
    "        \n",
    "        if verbose:\n",
    "            print(name)\n",
    "            print(f'start1: {start1} -- end1: {end1}')\n",
    "            print(f'start2: {start2} -- end2: {end2}')\n",
    "\n",
    "        if verbose > 1:\n",
    "            print(f'>mate1\\n{mate1}')\n",
    "            print(f'>mate1_rc\\n{reverse_complement(mate1)}')\n",
    "        if verbose > 1:\n",
    "            print(f'>mate2\\n{mate2}')\n",
    "            print(f'>mate2_rc\\n{reverse_complement(mate2)}')\n",
    "        \n",
    "        frame_number = 3 - ((start1 -1 )% 3) \n",
    "        if verbose > 1:\n",
    "            print(f'{frame_number} = (({start1} + 1) % 3) + 1')\n",
    "\n",
    "#         frame_number = ((start1)% 3) + 1\n",
    "\n",
    "        record_seq = record['sequence']\n",
    "        if verbose > 1:\n",
    "            print(f'>record\\n{record_seq}')\n",
    "            print(f'>record_rc\\n{reverse_complement(record_seq)}')\n",
    "\n",
    "        if verbose:\n",
    "            print('--- Trying mate 1 ---')\n",
    "        strand = get_strand(mate1, record_seq)\n",
    "        if verbose and strand is not None:\n",
    "            if strand > 0:\n",
    "                print('mate1')\n",
    "            if strand < 0:\n",
    "                print('mate1, reverse complement')\n",
    "\n",
    "        \n",
    "        if strand is None:\n",
    "            if verbose:\n",
    "                print('--- Not mate1, trying mate 2 ---')\n",
    "            # Maybe it's mate2?\n",
    "#             strand = -1\n",
    "            strand = get_strand(mate2, record_seq)\n",
    "            frame_number = 3 - ((start2 - 1 ) % 3)\n",
    "            \n",
    "            if verbose and strand is not None:\n",
    "                print(f'{frame_number} = (({start2} + 1) % 3) + 1')\n",
    "                if strand > 0:\n",
    "                    print('mate2')\n",
    "                if strand < 0:\n",
    "                    print('mate2, reverse complement')\n",
    "                \n",
    "\n",
    "        # Multiply the frame number by the strand multiplier\n",
    "        try:\n",
    "            frame = frame_number * strand\n",
    "            if verbose:\n",
    "                print(f'{frame} = {frame_number} * {strand}')\n",
    "        except TypeError:\n",
    "            # Strand is still none, don't know what's going on so skip this read\n",
    "            frame = None\n",
    "    return frame\n",
    "            \n",
    "\n",
    "def fastq_per_read_frame(fastq, verbose=False):\n",
    "    read_id_to_frame = {}\n",
    "    with screed.open(fastq) as records:\n",
    "        for record in tqdm(records):\n",
    "    #         if 'read52/' in record['name']:\n",
    "    #             break\n",
    "            if verbose:\n",
    "                print('\\n---')\n",
    "            frame = get_correct_reading_frame(record, required_length=150, verbose=verbose)\n",
    "            if verbose:\n",
    "                print(f'frame: {frame}')\n",
    "            if frame is not None:\n",
    "                read_id_to_frame[record['name']] = frame\n",
    "\n",
    "    read_id_to_frame_series = pd.Series(read_id_to_frame, name='translation_frame')\n",
    "    print(read_id_to_frame_series.shape)\n",
    "    read_id_to_frame_series.head()\n",
    "    return read_id_to_frame_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make mini fastq for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for read_id in protein_k11_good_uniprot_ids_no_ns_coding.sample(5).read_id.values:\n",
    "\n",
    "#     ! zgrep -A 3 \"$read_id\" $reads_dir/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file mini.fastq\n",
    "@read51/sp|A0A024RBG1|ENSP00000492425;mate1:130-279;mate2:281-430__frame=-3\n",
    "GCTTTTCCAGATACTCTGCATGTACAGGTTTATGACACTGGAGAACTTTGATAGCATCTTCTACTTTGAACCACTCTCTCTTCCTTCCAATATTAACAGAATCTTCCCAATCTTCTAATATTTCAGTGACTGTTAGAACATAAACATATG\n",
    "+\n",
    "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "@read52/sp|A0A024RBG1|ENSP00000492425;mate1:125-274;mate2:193-342__frame=3\n",
    "ACCCAGACCAGTGGATTGTCCCAGGAGGAGGAATGGAACCCGAGGAGGAACCTGGCGGTGCTGCCGTGAGGGAAGTTTATGAGGAGGCTGGAGTCAAAGGAAAACTAGGCAGACTTCTGGGCATATTTGAGCAGAACCAAGACCGAAAGC\n",
    "+\n",
    "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "@read302822/sp|P49760|ENSP00000460443;mate1:755-904;mate2:890-1039__frame=3\n",
    "ATTTCCTCAAAGACAACAACTACCTGCCCTACCCCATCCACCAAGTGCGCCACATGGCCTTCCAGCTGTGCCAGGCTGTCAAGTTCCTCCATGATAACAAGCTGACACATACAGACCTCAAGCCTGAAAATATTCTGATTGTGAATTCAG\n",
    "+\n",
    "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "@read780376/sp|Q96PL2|ENSP00000494896;mate1:747-896;mate2:829-978__frame=2\n",
    "CCNGTTCCAGAACATCCCCAAACTCTCCAAGGTGTGGTTACACTGTGAGACGTTCATCTGCGACAGTGAGAAACTCTCCTGCCCAGTGACCTGCGATAAACGGAAGCGCCTCCTGCGAGACCAGACCGGGGGAGTCCTGGTCGTGGAGCT\n",
    "+\n",
    "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "@read192484/sp|P09629|ENSP00000239165;mate1:19-168;mate2:125-274__frame=1\n",
    "GCGAATACTTTATTTTCTAAATATCCAGCCTCAAGTTCGGTTTTCGCTACCGGAGCCTTCCCAGAACAAACTTCTTGTGCGTTTGCTTCCAACCCCCAGCGCCCGGGCTATGGAGCGGGTTCGGGCGCTTCCTTCGCCGCCTCGATGCAG\n",
    "+\n",
    "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "@read335141/sp|P60368|ENSP00000375479;mate1:141-290;mate2:251-400__frame=2\n",
    "CACCCCAGTGAGCTGTGTGTCCAGCCCCTGCTGCCAGGCGGCCTGTGAGCCCAGCGCCTGCCAATCAGGCTGCACCAGCTCCTGCACGCCCTCGTGCTGCCAGCAGTCTAGCTGCCAGCCGGCTTGCTGCACCTCCTCCCCCTGCCAGCA\n",
    "+\n",
    "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "@read494460/sp|Q5VWX1|ENSP00000281156;mate1:81-230;mate2:193-342__frame=2\n",
    "TTTGGCAGAAGAAATTGAAAAGTTTCAAGGTTCTGATGGAAAAAAGGAAGACGAAGAAAAGAAGTATCTTGATGTCATCAGCAACAAAAACATAAAGCTCTCAGAAAGAGTACTGATTCCTGTCAAGCAGTATCCAAAGTTCAATTTTGT\n",
    "+\n",
    "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "@read734191/sp|Q96A65|ENSP00000376868;mate1:842-991;mate2:949-1098__frame=-1\n",
    "AGTGTCCTGCAGGTATCCCAGGACCACAGAGTGTGCAGCGGCTACAGCATTAAACTTGTCAAACAGTAACTCCAGCAGTTCTAGAAGCAACCTTGGTTGGTTCTCCACAGTAACGTTCTCCCCCCGCTGATAGCCACTGTCTGCCACCTG\n",
    "+\n",
    "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "@read640286/sp|Q8N7Q2|BAC05176;mate1:30-179;mate2:140-289__frame=?\n",
    "TTTGGCCAACTTCGCCTCTTCAATTAAAAGGACACATGCTGTTAACGGGTGCTGTGGATTACAGATGATCGCACTCTGGGCACAGTCCTCTGGAAATGCAGATGCCCGTGTGGAGGAAATTCTGGCGGGAGAGGAGCGGCGACTCGCCGC\n",
    "+\n",
    "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "@read325914/sp|P56278|ENSP00000358488;mate1:12-161;mate2:125-274__frame=2\n",
    "GGATGTGGGGGCTCCACCCGATCACCTCTGGGTTCACCAAGAGGGTATCTACCGCGACGAATACCAGCGCACGTGGGTGGCCGTCGTGGAAGAGGAGACGAGTTTCCTAAGGGCACGAGTCCAGCAAATTCAGGTTCCCTTAGGTGACGC\n",
    "+\n",
    "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "@read714894/sp|Q8WYR1|ENSP00000485280;mate1:570-719;mate2:662-811__frame=2\n",
    "GAGCCAGACGCCCTCACCCCCGACAGACTCCCCTAGGCACGCCAGCCCTGGAGAGCTGGGCACCACCCCATGGGAGGAGAGCACCAATGACATCTCCCACTACCTCGGCATGCTGGACCCCTGGTATGAGCGCAATGTACTGGGCCTCAT\n",
    "+\n",
    "IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on mini dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_results = fastq_per_read_frame('mini.fastq', verbose=2)\n",
    "mini_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make ground truth dataframe for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "s = '''read_id\ttrue_mate\ttrue_frame\tguessed_frame\n",
    "read51/sp|A0A024RBG1|ENSP00000492425;mate1:130-279;mate2:281-430\tmate2_rc\t-3\t-3\n",
    "read52/sp|A0A024RBG1|ENSP00000492425;mate1:125-274;mate2:193-342\tmate1\t3\t2\n",
    "read302822/sp|P49760|ENSP00000460443;mate1:755-904;mate2:890-1039\tmate1\t3\t2\n",
    "read780376/sp|Q96PL2|ENSP00000494896;mate1:747-896;mate2:829-978\tmate1\t2\t3\n",
    "read192484/sp|P09629|ENSP00000239165;mate1:19-168;mate2:125-274\tmate1\t1\t1\n",
    "read335141/sp|P60368|ENSP00000375479;mate1:141-290;mate2:251-400\tmate1\t2\t3\n",
    "read494460/sp|Q5VWX1|ENSP00000281156;mate1:81-230;mate2:193-342\tmate1\t2\t3\n",
    "read734191/sp|Q96A65|ENSP00000376868;mate1:842-991;mate2:949-1098\tmate2_rc\t-1\t-2\n",
    "read640286/sp|Q8N7Q2|BAC05176;mate1:30-179;mate2:140-289\tmate1\t3\t2\n",
    "read325914/sp|P56278|ENSP00000358488;mate1:12-161;mate2:125-274\tmate1\t2\t3\n",
    "'''\n",
    "mini_df = pd.read_csv(StringIO(s), sep='\\t')\n",
    "mini_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_df['transcript_id'] = mini_df.read_id.map(lambda x: x.split(';')[0].split('/')[-1])\n",
    "mini_df['uniprot_id'] = mini_df.transcript_id.map(lambda x: '|'.join(x.split('|')[:2]))\n",
    "mini_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in mini_df.iterrows():\n",
    "    uniprot_id = row['uniprot_id']\n",
    "    print(f'\\n---\\n{row.read_id}')\n",
    "    print(good_uniprot_records_dict[uniprot_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spot check some reading frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run code to assign correct reading frame to all read ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "read_id_to_frame_series = fastq_per_read_frame(fastq)\n",
    "print(read_id_to_frame_series.shape)\n",
    "read_id_to_frame_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_id_to_frame_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write correct reading frames to file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# human_busco_dir = \"/mnt/ibm_sm/home/olga/pipeline-results/human-simulated/nf-predictorthologs--busco-mammalia-human\"\n",
    "csv = os.path.join(ORPHEUM_BENCHMARKING_FOLDER, \"correct_reading_frames.csv\")\n",
    "read_id_to_frame_series.to_csv(csv, index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create gold standard classification data for all reading frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read gold standard series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "read_id_to_frame_series.index.name = 'read_id'\n",
    "read_id_to_frame = read_id_to_frame_series.reset_index()\n",
    "read_id_to_frame['is_coding'] = True\n",
    "read_id_to_frame['read_id_frame'] = read_id_to_frame.read_id.astype(str) + '__frame=' + read_id_to_frame.translation_frame.astype(str)\n",
    "read_id_to_frame = read_id_to_frame.set_index('read_id_frame')\n",
    "print(read_id_to_frame.shape)\n",
    "read_id_to_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make cartesian product of read id and frames with `itertools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = (1, 2, 3, -1, -2, -3)\n",
    "all_read_id_frames = [\n",
    "    f\"{read_id}__frame={frame}\"\n",
    "    for read_id, frame in itertools.product(read_id_to_frame[\"read_id\"], frames)\n",
    "]\n",
    "len(all_read_id_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make true coding frame series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_coding_frame = pd.Series(False, index=all_read_id_frames, name='is_coding')\n",
    "true_coding_frame[read_id_to_frame.index] = True\n",
    "true_coding_frame.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_coding_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basename = \"true_reading_frames\"\n",
    "\n",
    "parquet = os.path.join(ORPHEUM_GROUND_TRUTH_FOLDER, f\"{basename}.parquet\")\n",
    "csv = os.path.join(ORPHEUM_GROUND_TRUTH_FOLDER, f\"{basename}.csv\")\n",
    "\n",
    "true_coding_frame.to_frame().to_parquet(parquet)\n",
    "true_coding_frame.to_csv(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_coding_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kmer-homology]",
   "language": "python",
   "name": "conda-env-kmer-homology-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
